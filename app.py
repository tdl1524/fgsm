import streamlit as st
import torch
import torchvision.transforms as transforms
import torchvision
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# --- CÃ i Ä‘áº·t thiáº¿t bá»‹ ---
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# --- Load model pretrained ---
@st.cache_resource
def load_model():
    model = torchvision.models.resnet34(weights='IMAGENET1K_V1')
    model.eval()
    for param in model.parameters():
        param.requires_grad = False
    model.to(device)
    return model

model = load_model()

# --- GiÃ¡ trá»‹ mean vÃ  std Ä‘á»ƒ normalize theo ImageNet ---
NORM_MEAN = np.array([0.485, 0.456, 0.406])
NORM_STD = np.array([0.229, 0.224, 0.225])

plain_transforms = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=NORM_MEAN, std=NORM_STD)
])

# --- HÃ m hiá»ƒn thá»‹ áº£nh ---
def imshow(img_tensor, title=""):
    img = img_tensor.cpu().permute(1, 2, 0).numpy()
    img = img * NORM_STD + NORM_MEAN
    img = np.clip(img, 0, 1)

    fig, ax = plt.subplots()
    ax.imshow(img)
    ax.axis('off')
    if title:
        ax.set_title(title)
    st.pyplot(fig)

# --- HÃ m FGSM ---
def fast_gradient_sign_method(model, imgs, labels, epsilon=0.02):
    imgs = imgs.clone().detach().to(device).requires_grad_(True)
    output = model(imgs)
    loss = torch.nn.functional.nll_loss(torch.nn.functional.log_softmax(output, dim=1), labels.to(device))
    model.zero_grad()
    loss.backward()
    grad_sign = imgs.grad.data.sign()
    adv_imgs = imgs + epsilon * grad_sign
    # Clamp theo normalize
    for c in range(3):
        adv_imgs[:, c, :, :] = torch.clamp(adv_imgs[:, c, :, :], (0 - NORM_MEAN[c]) / NORM_STD[c], (1 - NORM_MEAN[c]) / NORM_STD[c])
    return adv_imgs.detach(), grad_sign

# --- App ---
st.set_page_config(page_title="FGSM Attack Demo", layout="centered")
st.title("âš”ï¸ Demo Táº¥n cÃ´ng Adversarial (FGSM) trÃªn ResNet34")

uploaded_file = st.file_uploader("ğŸ“¤ Upload má»™t áº£nh JPG/PNG", type=["jpg", "jpeg", "png"])
epsilon = st.slider("âš™ï¸ Chá»n epsilon (má»©c Ä‘á»™ nhiá»…u)", 0.0, 0.2, 0.02, 0.01)

if uploaded_file is not None:
    img = Image.open(uploaded_file).convert("RGB")
    st.image(img, caption="áº¢nh gá»‘c", use_container_width=True)

    input_tensor = plain_transforms(img).unsqueeze(0).to(device)

    # Dá»± Ä‘oÃ¡n áº£nh gá»‘c
    with torch.no_grad():
        output = model(input_tensor)
    pred_class = output.argmax(dim=1).item()

    st.write(f"ğŸ“Œ Dá»± Ä‘oÃ¡n áº£nh gá»‘c: **Class ID = {pred_class}**")

    # GÃ¡n nhÃ£n giáº£ Ä‘á»ƒ táº¥n cÃ´ng (dÃ¹ng chÃ­nh nhÃ£n mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n)
    label = torch.tensor([pred_class]).to(device)

    # Táº¡o áº£nh nhiá»…u
    adv_img, noise = fast_gradient_sign_method(model, input_tensor, label, epsilon)

    st.write("ğŸ–¼ï¸ áº¢nh sau khi thÃªm nhiá»…u:")
    imshow(adv_img[0])

    # Dá»± Ä‘oÃ¡n láº¡i trÃªn áº£nh nhiá»…u
    with torch.no_grad():
        adv_output = model(adv_img)
    adv_class = adv_output.argmax(dim=1).item()

    st.write(f"ğŸ“Œ Dá»± Ä‘oÃ¡n áº£nh Ä‘Ã£ nhiá»…u: **Class ID = {adv_class}**")

    # ÄÆ°a ra nháº­n xÃ©t
    if pred_class != adv_class:
        st.error("ğŸ’¥ MÃ´ hÃ¬nh Ä‘Ã£ bá»‹ Ä‘Ã¡nh lá»«a! Dá»± Ä‘oÃ¡n Ä‘Ã£ thay Ä‘á»•i.")
    else:
        st.success("âœ… MÃ´ hÃ¬nh váº«n nháº­n diá»‡n Ä‘Ãºng dÃ¹ Ä‘Ã£ bá»‹ táº¥n cÃ´ng.")
